{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#загрузка-данных,-просмотр\" data-toc-modified-id=\"загрузка-данных,-просмотр-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>загрузка данных, просмотр</a></span></li><li><span><a href=\"#подготовка-данных-к-обучению\" data-toc-modified-id=\"подготовка-данных-к-обучению-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>подготовка данных к обучению</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#DecissionTreeClassifier\" data-toc-modified-id=\"DecissionTreeClassifier-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>DecissionTreeClassifier</a></span></li><li><span><a href=\"#RandomForestClassifier\" data-toc-modified-id=\"RandomForestClassifier-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>RandomForestClassifier</a></span></li><li><span><a href=\"#CatBoostClassifier\" data-toc-modified-id=\"CatBoostClassifier-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>CatBoostClassifier</a></span></li><li><span><a href=\"#Таким-образом,-лучшие-показатели-f1-дала-модель-LogisticRegresion.-Попробуем-их-улучшить\" data-toc-modified-id=\"Таким-образом,-лучшие-показатели-f1-дала-модель-LogisticRegresion.-Попробуем-их-улучшить-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Таким образом, лучшие показатели f1 дала модель LogisticRegresion. Попробуем их улучшить</a></span></li><li><span><a href=\"#Дообучим-выбранную-модель-на-всех-оставшихся-данных-перед-финальной-и-проведем-тест-на-тестовой-выборке.\" data-toc-modified-id=\"Дообучим-выбранную-модель-на-всех-оставшихся-данных-перед-финальной-и-проведем-тест-на-тестовой-выборке.-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Дообучим выбранную модель на всех оставшихся данных перед финальной и проведем тест на тестовой выборке.</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zf8THTc1XGLP"
   },
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Kqe_WXmXGLQ"
   },
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "decbRTd_XGLQ"
   },
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GK6enRMtXGLR"
   },
   "source": [
    "### загрузка данных, просмотр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cMglcXGXgNb",
    "outputId": "f9cf1ab1-4cb4-4e43-bc3f-7c314457087d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /opt/conda/lib/python3.9/site-packages (1.0.3)\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.9/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.9/site-packages (from catboost) (1.2.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from catboost) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.9/site-packages (from catboost) (1.21.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from catboost) (3.3.4)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.9/site-packages (from catboost) (5.4.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2021.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from plotly->catboost) (8.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ez14fQtzXGLR"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xnwSPuuKXGLU",
    "outputId": "79dde040-f198-4292-c54e-df192cc54589"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords') \n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "kKln3uMxXGLS",
    "outputId": "28e734d4-d20d-4b7d-e4fa-e4da7af67a60"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "    \n",
    "except:\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "    data = pd.read_csv(io.BytesIO(uploaded['toxic_comments.csv']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYSvMz9w77ME"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> Огонь, данные на месте:)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "idhOTZGeXGLS",
    "outputId": "e5a4c277-ab3e-4c43-fc7b-33e47a0c9621",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unnamed: 0    0\n",
      "text          0\n",
      "toxic         0\n",
      "dtype: int64\n",
      "Unnamed: 0    16186\n",
      "text          16186\n",
      "toxic         16186\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.info())\n",
    "display(data.head())\n",
    "print()\n",
    "print(data.isnull().sum().sort_values(ascending=False).head(10))\n",
    "data_original = data\n",
    "print(data[data['toxic']==1].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq2E1i5XXGLT"
   },
   "source": [
    "для анализа и обучения предоставлены 159 тысяч текстов с оценкой их токсичности, 16 тысяч текстов токсичны. в данных нет пропусков, формат соответвует назначению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hL6rh17277MF"
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Комментарий ревьюера ❌:</b>Данные также необходимо очистить от мусора и привести в начальную форму с помощью WordNetLemmatizer:\n",
    "    \n",
    "+  https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nO2SRXGsDoVW"
   },
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> сделал лемматизацию через WordNet, убрал знаки препинания, мешок стал ощутимо меньше. Спасибо!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lzJ9K1GmB2--",
    "outputId": "1da08c6f-0553-4543-fdba-14e54714777a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Explanation Why the edits made under my userna...\n",
      "1    D aww He matches this background colour I m se...\n",
      "2    Hey man I m really not trying to edit war It s...\n",
      "3    More I can t make any real suggestions on impr...\n",
      "4    You sir are my hero Any chance you remember wh...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clear_text(text):\n",
    "    t = re.sub(r'[^a-zA-Z ]', ' ', text) \n",
    "    t_list = t.split()\n",
    "    t_text = ' '.join(t_list)\n",
    "    return t_text\n",
    "for i in data.index:\n",
    "    data.loc[i, 'text'] = lemmatizer.lemmatize(clear_text(data.loc[i,'text']))\n",
    "print(data['text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISRlGOzGa0ck"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера V2✔️:</b>`\n",
    "    \n",
    "Так же можешь попробовать использовать spacy:\n",
    "    \n",
    "```python\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemmatize_spacy(text):\n",
    "    return \" \".join([token.lemma_ for token in nlp(text)])\n",
    "\n",
    "data['lemm_spacy'] = data['text'].progress_apply(lemmatize_spacy)     \n",
    "```\n",
    "\n",
    "Вот так можно следить за выполнением функции (как раз выше его использовал)\n",
    "\n",
    "```python\n",
    "    \n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "data['text'] = data['text'].progress_apply(lemmatize_text) \n",
    "```\n",
    "Где *lemmatize_text* - функция\n",
    "\n",
    "    \n",
    "P.S Кстати можно ускорить spacy ( раз в 5 +-)\n",
    "    \n",
    "```python\n",
    "new_corpus = []\n",
    "\n",
    "for doc in tqdm(nlp.pipe(data['text'], batch_size=64, n_process=-1, disable=[\"parser\", \"ner\"]), total=len(data['text'])):\n",
    "    word_list = [tok.lemma_ for tok in doc]\n",
    "    new_corpus.append(' '.join(word_list))\n",
    "    \n",
    "data['lemm_spacy_new'] = new_corpus   \n",
    "    \n",
    "    \n",
    "```\n",
    "    \n",
    "Для больших объемов текста ```SpaCy``` рекомендует использовать ```nlp.pipe```, который может работать в пакетах ```batch_size```(Допустим ```batch_size=64```, тогда все наши данные делятся на 64 пакета (как прям в фолдах, только там мы пишем число на сколько поделить наши данные (3/5/10 частей),а тут пишем, сколько данных отдать в обработку)  и имеет встроенную поддержку многопроцессорной обработки ```n_process``` (аналог ```n_jobs``` для GridSearchCV).\n",
    "\n",
    "Кроме того, нужно убедиться, что мы отключили все элементы конвейера, которые мы не планируем использовать, поскольку они просто потратят время на обработку. Если мы выполняем только лемматизацию, то необходимо передать ```disable=[\"parser\", \"ner\"]``` к ```nlp.pipe```.\n",
    "    \n",
    "    \n",
    "P.S.S Если запустишь ```nlp.pipe```, то первое время нужно подождать прежде, чем начнется обработка \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_a02BUTXGLU"
   },
   "source": [
    "### подготовка данных к обучению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBw6YscpXGLU",
    "outputId": "b824d643-6142-4c5b-bbeb-b2624d924981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50974,)\n",
      "(50974,)\n",
      "(31859,)\n",
      "(31859,)\n"
     ]
    }
   ],
   "source": [
    "#создадим валидационную и тестовую выборки, тренировочную уменьшим\n",
    "rand = 12345\n",
    "remaining, test = train_test_split(\n",
    "    data, \n",
    "    test_size=0.20, \n",
    "    stratify = data['toxic'], \n",
    "    random_state = rand\n",
    ")\n",
    "\n",
    "leftovers, train = train_test_split(\n",
    "    remaining, \n",
    "    test_size=0.4, \n",
    "    stratify = remaining['toxic'], \n",
    "    random_state = rand\n",
    ")\n",
    "\n",
    "\n",
    "x_train = train['text']\n",
    "y_train = train['toxic']\n",
    "x_test = test['text']\n",
    "y_test = test['toxic']\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxLbM3AF77MG"
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Комментарий ревьюера ❌:</b> В дальнейшем используешь GridSearchCV, который основан на кросс валидации, поэтому использование валидации избыточно. Лучше соединить обучающую и валидационную выборку, так мы больше данных выучим, а значит лучше научимся обобщать их\n",
    "\n",
    "+  https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right\n",
    "+  https://academy.yandex.ru/handbook/ml/article/kross-validaciya\n",
    "\n",
    "P.S С помощью `model.best_score_` можно узнать лучшую метрику у GridSearchCV\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFr2fTxZ77MG"
   },
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> убрал валидационную выборку и все операции с ней, но не стал расширять тренировочную, чтобы не усложнять выбор модели. Она все будет частью \"remaining\", на которой будем проводить финальное обучение выбранной модели.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sK4ECNjia0cl"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера V2✔️:</b>Хорошо\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWAO3gfsXGLV",
    "outputId": "2dc72261-0c5d-4410-f1e5-6cfb00fbc0c4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер мешка с учётом стоп-слов: (50974, 86969)\n"
     ]
    }
   ],
   "source": [
    "corpus_train = x_train.values\n",
    "\n",
    "count_vect = CountVectorizer(stop_words=nltk_stopwords.words('russian'))\n",
    "bow_train = count_vect.fit_transform(corpus_train) \n",
    "\n",
    "print(\"Размер мешка с учётом стоп-слов:\", bow_train.shape)\n",
    "#print(bow_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zt8tQP0y77MH"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера ⚠️:</b> Перевод в unicode актуально для русского языка, который был в тренажере, в данной задаче это делать нет необходимости\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxaN-3OY77MH"
   },
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Убрал, спасибо!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zer1uCXEXGLW",
    "outputId": "3ed9a03f-0c62-422d-ef5a-fc233efcba70",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер мешка с учётом стоп-слов: (31859, 86969)\n"
     ]
    }
   ],
   "source": [
    "corpus_test = x_test.values\n",
    "\n",
    "bow_test = count_vect.transform(corpus_test) \n",
    "\n",
    "print(\"Размер мешка с учётом стоп-слов:\", bow_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iymtPif77MI"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> Отлично, молодец, верно используешь Tfidf.\n",
    "    \n",
    "    \n",
    "Совет: Внутри кросс-валидации происходит разбиение выборки на train и valid. Однако, в таком случае векторизатор обучен на всей выборке(train), а это не совсем корректно. Чтобы избежать это можно воспользоваться Pipeline:\n",
    "    \n",
    "```python\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('logreg', LogisticRegression(random_state=42)),\n",
    "])\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'logreg__C': [1,2,6]\n",
    "}\n",
    "\n",
    "grid_search_tune = RandomizedSearchCV(pipeline, parameters, cv=3, n_jobs=-1, scoring='f1', verbose=3)\n",
    "grid_search_tune.fit(train_features, train_targets)\n",
    "  \n",
    "    \n",
    "```\n",
    "    \n",
    "Это просто каркас, можешь сам выбрать какие параметры использовать для подбора:) \n",
    "    \n",
    "+  https://runebook.dev/ru/docs/scikit_learn/modules/generated/sklearn.model_selection.halvinggridsearchcv - тут про HalvingGridSearchCV\n",
    "    \n",
    "+  https://www.rupython.com/python-sklearn-pipeline-pipeline-28301.html - про pipeline\n",
    "+  https://towardsdatascience.com/how-to-use-sklearn-pipelines-for-ridiculously-neat-code-a61ab66ca90d\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwOrJ9qGXGLW"
   },
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_EhNorGXGLW"
   },
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LaBQOnMpXGLW",
    "outputId": "00a5ddf5-c9b5-44fc-8323-a96e49775c93"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "log_param = {\n",
    "    'C': range(1, 11, 2),\n",
    "    'solver': ['lbfgs', 'newton-cg', 'sag'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(\n",
    "                    LogisticRegression(class_weight = 'balanced'), \n",
    "                    param_grid = log_param, \n",
    "                    cv=5, \n",
    "                    scoring='f1'\n",
    "                    )\n",
    "grid.fit(bow_train, y_train)\n",
    "print('Лучшая регрессия', grid.best_estimator_)\n",
    "log = grid.best_estimator_\n",
    "print('f1 регрессии', grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJrKvfCcXGLX",
    "outputId": "8f5767d1-c95b-42b3-c73c-48a16601a40a",
    "scrolled": true
   },
   "source": [
    "predict_log = log.predict(bow_valid)\n",
    "print(predict_log)\n",
    "print(predict_log.sum())\n",
    "print(y_valid.sum())\n",
    "print(metrics.f1_score(y_valid, predict_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-C7D9GK77MJ"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера ⚠️:</b> Кросс валидации хватит вполне, чтобы оценить модель\n",
    "    \n",
    "    \n",
    "Для LogisticRegression по подбирай параметр C (коэффициент регуляризации)\n",
    "\n",
    "    \n",
    "+  ```class_weight: [None, 'balanced']``` - да, у нас есть дисбаланс, но вдруг модель и без изменения весов получит лучше результат\n",
    "+  ```C: range(1, 11, 2)``` - от 1 до 11 с шагом 2 это параметр регуляризации (должен помочь)\n",
    "    \n",
    "    \n",
    "Для подбора лучше использовать `GridSearchCV` \n",
    "    \n",
    "    \n",
    "```python\n",
    "param = { 'C': range(1, 11, 2), 'class_weight': [None, 'balanced'] }\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "\n",
    "# инициализируем GridSearchCV\n",
    "cv_lr = GridSearchCV(estimator = model_lr, \n",
    "                           param_grid = param, \n",
    "                           cv = 3,\n",
    "                           n_jobs = -1, \n",
    "                           verbose = 0, \n",
    "                           scoring = 'f1',\n",
    "                          )\n",
    "cv_lr.fit(tf_idf_train, target_train)    \n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESuGZXqLXGLX"
   },
   "source": [
    "уже хороший результат, проходим по метрикам, посмотрим другие модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfpiv-CEXGLX"
   },
   "source": [
    "### DecissionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zbbSW6OWXGLY",
    "outputId": "cf8cb20c-3350-4e5a-8baa-c74092270f42"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#DecisionTreeClassifier\n",
    "\n",
    "tree_param = {\n",
    "            'max_depth':  range(1, 20),\n",
    "            'min_samples_leaf': [5, 10, 20]\n",
    "            #'min_samples_split': [5, 10, 20]\n",
    "            }\n",
    "\n",
    "grid = GridSearchCV(\n",
    "                    DecisionTreeClassifier(random_state=rand, \n",
    "                                           class_weight = 'balanced'), \n",
    "                    param_grid = tree_param, \n",
    "                    cv=5, \n",
    "                    scoring='f1'\n",
    "                    )\n",
    "grid.fit(bow_train, y_train)\n",
    "print('Лучшее дерево решений', grid.best_estimator_)\n",
    "print('f1 дерева', grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ygOD6_IfXGLY",
    "outputId": "4c7c4c51-510e-4733-d6d1-80bb5ca12777"
   },
   "outputs": [],
   "source": [
    "tree = grid.best_estimator_\n",
    "print('f1 дерева', grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASgdg962XGLY"
   },
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2QNROnyXGLZ",
    "outputId": "7f377916-3bcc-42c7-fbc7-0fcee9c174f9"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#RandomForestClassifier\n",
    "\n",
    "forest_param = {\n",
    "    'max_depth': range(1, 20),\n",
    "    'n_estimators': range(1, 20)\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(\n",
    "                    RandomForestClassifier(random_state=rand,\n",
    "                                          class_weight = 'balanced'), \n",
    "                    param_grid = forest_param, \n",
    "                    cv=5, \n",
    "                    scoring='f1'\n",
    "                    )\n",
    "grid.fit(bow_train, y_train)\n",
    "print('Лучший лес', grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CGlH8FeqXGLZ",
    "outputId": "74f8d71b-21a0-49ec-f538-5bf71f2025f6"
   },
   "outputs": [],
   "source": [
    "forest = grid.best_estimator_\n",
    "print('f1 леса', grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrWSAzkbXGLZ"
   },
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5Sa22I6XGLZ",
    "outputId": "0e11716c-4919-4ec0-aa8b-545ffa12f2f4"
   },
   "source": [
    "%%time\n",
    "\n",
    "# CatBoostClassifier\n",
    "#из-за долгого обучения, пришлось убрать почти все параметры из GridSearchCV\n",
    "cat_param = {\n",
    "            'depth'         : [5, 10]\n",
    "            #'learning_rate' : [0.1, 0.05]\n",
    "            #'iterations'    : [50, 100]\n",
    "            }\n",
    "\n",
    "grid = GridSearchCV(\n",
    "                    CatBoostClassifier(), \n",
    "                    param_grid = cat_param, \n",
    "                    cv=5, \n",
    "                    scoring='f1'\n",
    "                    )\n",
    "\n",
    "grid.fit(bow_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1W0x_d6AXGLa",
    "outputId": "c96ae172-0863-433c-d9de-9c3f4a74f030"
   },
   "source": [
    "cbr =  grid.best_estimator_ \n",
    "print('f1 CatBoost', grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_wnoEl9XGLa"
   },
   "source": [
    "обучение модели CatBoost показало низкие результаты, несмотря на огромные ресурсы и время обучения. в связи с этим, я перевел ячейки в текстовый формат, чтобы не повторять его каждый раз. при необходимости и для наглядности, их можно использовать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfUJro9CXGLa"
   },
   "source": [
    "### Таким образом, лучшие показатели f1 дала модель LogisticRegresion. Попробуем их улучшить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-Md6mPwXGLb"
   },
   "source": [
    "### Дообучим выбранную модель на всех оставшихся данных перед финальной и проведем тест на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGeg98Jv77MN"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> Хорошо получилось:)  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aQxclE5iXGLb",
    "outputId": "2489e9ba-07aa-4703-f9f5-f3c06347eaf5"
   },
   "outputs": [],
   "source": [
    "corpus_remaining = remaining['text'].values\n",
    "\n",
    "count_vect = CountVectorizer(stop_words=nltk_stopwords.words('russian'))\n",
    "bow_remaining = count_vect.fit_transform(corpus_remaining) \n",
    "\n",
    "print(\"Размер мешка с учётом стоп-слов:\", bow_remaining.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "svLqIEobXGLc",
    "outputId": "76b9fe7f-d750-487c-8251-2f60f2de4aef"
   },
   "outputs": [],
   "source": [
    "corpus_test = x_test.values\n",
    "\n",
    "bow_test = count_vect.transform(corpus_test) \n",
    "\n",
    "print(\"Размер мешка с учётом стоп-слов:\", bow_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "_dMiLsFmXGLc",
    "outputId": "d9d6b913-fe24-454d-8e0e-adc0211d3908",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log.fit(bow_remaining, remaining['toxic'])\n",
    "# y_pred = log.predict(X_test)  # default threshold is 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5A3lraMyTf6i",
    "outputId": "69338756-482e-44cc-fc46-049824e9cb74"
   },
   "outputs": [],
   "source": [
    "log_predict_proba = cross_val_predict(log, bow_remaining, remaining['toxic'], cv=2, method='predict_proba')\n",
    "print(log_predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "MvPpkX_KXGLb",
    "outputId": "9b8d90b8-3133-43a9-fbd2-ee3e2ea6bfcb"
   },
   "outputs": [],
   "source": [
    "log_predict_proba1 = log_predict_proba[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(remaining['toxic'], log_predict_proba1)\n",
    "auc = metrics.roc_auc_score(remaining['toxic'], log_predict_proba1)\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrwQi8jWXGLc",
    "outputId": "0e8bceba-abc6-4198-b41e-732ce98e05c4"
   },
   "outputs": [],
   "source": [
    "f1 = 0.0\n",
    "threshold = 0.1\n",
    "for thresh in range(1, 9):\n",
    "  predict_cv_proba = (log_predict_proba1 >= thresh/10).astype(bool) \n",
    "  #print(i)\n",
    "#   print(predict_cv.sum())\n",
    "  #print(y_test.sum())\n",
    "  print(metrics.f1_score(remaining['toxic'], predict_cv_proba))\n",
    "  if f1<metrics.f1_score(remaining['toxic'], predict_cv_proba):\n",
    "      threshold = thresh/10\n",
    "      f1 = metrics.f1_score(remaining['toxic'], predict_cv_proba)\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XlKm-CkT77MO",
    "outputId": "84bd263a-fe9d-4416-fe27-12b7bde31a36"
   },
   "outputs": [],
   "source": [
    "predict_log = log.predict(bow_test)\n",
    "print(predict_log)\n",
    "print(predict_log.sum())\n",
    "print(y_test.sum())\n",
    "print(metrics.f1_score(y_test, predict_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIN0f1EYNR-y",
    "outputId": "02a0508e-859d-404f-b727-b897b90f6f60"
   },
   "outputs": [],
   "source": [
    "predict_final = (log.predict_proba(bow_test)[:,1] >= threshold).astype(bool) \n",
    "print(predict_final)\n",
    "print(predict_final.sum())\n",
    "print(y_test.sum())\n",
    "print(metrics.f1_score(y_test, predict_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-NSrHre77MP"
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера ⚠️:</b> Хорошо, но как этот порог нашел?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiFObYw177MP"
   },
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> нашел по графику ROC, оптимизироваk циклом)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wR8R_K2ya0cp"
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Комментарий ревьюера V2❌:</b>  Тест имитирует продакшен, где мы чудом знаем ответом. В реальной жизни, не сможешь подобрать threshold, так как мы не знаем истинных меток для данных. Поэтому подобная операция проводится ТОЛЬКО на валидации или с помощью cross_val_predict(попробуй через него):\n",
    "    \n",
    "+  https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html\n",
    "    \n",
    "P.S Вообще делай так, избавляйся от теста сразу (убирай его в сторону), у нас только train есть. Как только подобрал лучшую модель, то все, что мы узнали на обучающей выборке мы переносим на тест (никакую информацию получать с теста нельзя) </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T431MB9rr7rn"
   },
   "source": [
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Спасибо! достал вероятности из кросс-валидационной проверки, сделал подбор отсечки оттуда. Получилось выиграть приблизительно 0.01%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "4wP7Rzb4gzlj",
    "outputId": "4c8875a6-f2b7-4980-f127-397e96202e51"
   },
   "outputs": [],
   "source": [
    "\n",
    "disp = metrics.ConfusionMatrixDisplay.from_estimator(\n",
    "        log,\n",
    "        bow_test,\n",
    "        y_test,\n",
    "        cmap=plt.cm.Blues,\n",
    "        normalize='true',\n",
    "    )\n",
    "disp.ax_.set_title('Матрица')\n",
    "\n",
    "print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rerjVa3MXGLc"
   },
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "207wZckMXGLd"
   },
   "source": [
    "    * Для классификации комментариев были предоставлены 160 тысяч текстов с проведенной категоризацией.\n",
    "    * Данные предоставлены в подходящем формате, пропусков и ошибок в них не обнаружено.\n",
    "    * Для выбора модели использовалась половина данных из-за ограниченности вычислительных ресурсов.\n",
    "    * Наилучшие результаты показала логистическая регрессия, ее показатель на валидационной выборке составил болеее 76 %. Дальнейшая работа велась с этой моделью.\n",
    "    * На основании ROC-кривой было принято решение увеличить отсеку до 80% вероятности. Это прибавило к метрике f1 еще около 3%.\n",
    "    \n",
    "    Вывод:\n",
    "    Для анализа текстов из библиотеки sklearn больше всего подходит модель LogisticRegression. \n",
    "    \n",
    "    комментарии классифицированы.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6tUxNX677MQ"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> \n",
    "\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множество реализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYae90ooXGLd"
   },
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leIeSSbbXGLd"
   },
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoEQHww377MQ"
   },
   "source": [
    "<font color='blue'><b>Итоговый комментарий ревьюера</b></font>\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b>Александр, получился хороший проект! \n",
    "    \n",
    "Если есть  если есть какие либо вопросы я с удовольствием на них отвечу:) <br> Исправь, пожалуйста, замечания и жду проект на следующую проверку:) </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nj-TRzWD77L7"
   },
   "source": [
    "<div style=\"border:solid green 2px; padding: 20px\">\n",
    "<b>Привет, Александр!</b>\n",
    "\n",
    "Меня зовут Александр Пономаренко, и я буду проверять твой проект. Предлагаю общаться на «ты» :) Но если это не удобно - дай знать, и мы перейдем на \"вы\". \n",
    "\n",
    "Моя основная цель — не указать на совершенные тобою ошибки, а поделиться своим опытом и помочь тебе стать data science. Ты уже проделал большую работу над проектом, но давай сделаем его еще лучше. Ниже ты найдешь мои комментарии - **пожалуйста, не перемещай, не изменяй и не удаляй их**. Увидев у тебя ошибку, в первый раз я лишь укажу на ее наличие и дам тебе возможность самой найти и исправить ее. На реальной работе твой начальник будет поступать так же, а я пытаюсь подготовить тебя именно к работе аналитиком. Но если ты пока не справишься с такой задачей - при следующей проверке я дам более точную подсказку. Я буду использовать цветовую разметку:\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Комментарий ревьюера ❌:</b> Так выделены самые важные замечания. Без их отработки проект не будет принят. </div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера ⚠️:</b> Так выделены небольшие замечания. Я надеюсь, что их ты тоже учтешь - твой проект от этого станет только лучше. Но настаивать на их отработке не буду.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера ✔️:</b> Так я выделяю все остальные комментарии.</div>\n",
    "\n",
    "Давай работать над проектом в диалоге: **если ты что-то меняешь в проекте или отвечаешь на мои комменатри — пиши об этом.** Мне будет легче отследить изменения, если ты выделишь свои комментарии:\n",
    "<div class=\"alert alert-info\"> <b>Комментарий студента:</b> Например, вот так.</div>\n",
    "\n",
    "Всё это поможет выполнить повторную проверку твоего проекта оперативнее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOMM1VKKa0ce",
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#загрузка-данных,-просмотр\" data-toc-modified-id=\"загрузка-данных,-просмотр-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>загрузка данных, просмотр</a></span></li><li><span><a href=\"#подготовка-данных-к-обучению\" data-toc-modified-id=\"подготовка-данных-к-обучению-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>подготовка данных к обучению</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#DecissionTreeClassifier\" data-toc-modified-id=\"DecissionTreeClassifier-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>DecissionTreeClassifier</a></span></li><li><span><a href=\"#RandomForestClassifier\" data-toc-modified-id=\"RandomForestClassifier-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>RandomForestClassifier</a></span></li><li><span><a href=\"#CatBoostClassifier\" data-toc-modified-id=\"CatBoostClassifier-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>CatBoostClassifier</a></span></li><li><span><a href=\"#Таким-образом,-лучшие-показатели-f1-дала-модель-LogisticRegresion.-Попробуем-их-улучшить\" data-toc-modified-id=\"Таким-образом,-лучшие-показатели-f1-дала-модель-LogisticRegresion.-Попробуем-их-улучшить-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Таким образом, лучшие показатели f1 дала модель LogisticRegresion. Попробуем их улучшить</a></span></li><li><span><a href=\"#Дообучим-выбранную-модель-на-всех-оставшихся-данных-перед-финальной-и-проведем-тест-на-тестовой-выборке.\" data-toc-modified-id=\"Дообучим-выбранную-модель-на-всех-оставшихся-данных-перед-финальной-и-проведем-тест-на-тестовой-выборке.-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Дообучим выбранную модель на всех оставшихся данных перед финальной и проведем тест на тестовой выборке.</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера V3✔️:</b> Удачи в следующих проектах!!!:)</div>"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1577,
    "start_time": "2023-03-28T17:38:56.025Z"
   },
   {
    "duration": 2976,
    "start_time": "2023-03-28T17:40:36.560Z"
   },
   {
    "duration": 65,
    "start_time": "2023-03-28T17:40:50.564Z"
   },
   {
    "duration": 60,
    "start_time": "2023-03-28T17:41:23.032Z"
   },
   {
    "duration": 61,
    "start_time": "2023-03-28T17:43:34.818Z"
   },
   {
    "duration": 59,
    "start_time": "2023-03-28T17:43:43.475Z"
   },
   {
    "duration": 169,
    "start_time": "2023-03-28T17:48:25.938Z"
   },
   {
    "duration": 2012,
    "start_time": "2023-03-28T17:50:01.238Z"
   },
   {
    "duration": 57,
    "start_time": "2023-03-29T11:18:35.284Z"
   },
   {
    "duration": 2832,
    "start_time": "2023-03-29T11:18:40.554Z"
   },
   {
    "duration": 3346,
    "start_time": "2023-03-29T11:18:43.389Z"
   },
   {
    "duration": 78,
    "start_time": "2023-03-29T11:18:46.737Z"
   },
   {
    "duration": 79,
    "start_time": "2023-03-29T11:18:46.817Z"
   },
   {
    "duration": 60,
    "start_time": "2023-03-29T11:19:33.312Z"
   },
   {
    "duration": 2129,
    "start_time": "2023-03-29T11:32:29.877Z"
   },
   {
    "duration": 56,
    "start_time": "2023-03-29T12:35:36.360Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-29T12:35:46.981Z"
   },
   {
    "duration": 1723,
    "start_time": "2023-03-29T12:35:53.752Z"
   },
   {
    "duration": 3255,
    "start_time": "2023-03-29T12:35:55.477Z"
   },
   {
    "duration": 74,
    "start_time": "2023-03-29T12:35:58.733Z"
   },
   {
    "duration": 47,
    "start_time": "2023-03-29T12:35:58.809Z"
   },
   {
    "duration": 8566,
    "start_time": "2023-03-29T12:35:58.858Z"
   },
   {
    "duration": 52,
    "start_time": "2023-03-29T12:36:38.250Z"
   },
   {
    "duration": 1605,
    "start_time": "2023-03-29T12:37:57.114Z"
   },
   {
    "duration": 3287,
    "start_time": "2023-03-29T12:37:58.721Z"
   },
   {
    "duration": 80,
    "start_time": "2023-03-29T12:38:02.009Z"
   },
   {
    "duration": 51,
    "start_time": "2023-03-29T12:38:02.092Z"
   },
   {
    "duration": 8130,
    "start_time": "2023-03-29T12:38:02.145Z"
   },
   {
    "duration": 1645,
    "start_time": "2023-03-29T12:38:59.837Z"
   },
   {
    "duration": 3360,
    "start_time": "2023-03-29T12:39:01.484Z"
   },
   {
    "duration": 73,
    "start_time": "2023-03-29T12:39:04.846Z"
   },
   {
    "duration": 56,
    "start_time": "2023-03-29T12:39:04.922Z"
   },
   {
    "duration": 163,
    "start_time": "2023-03-29T12:39:04.979Z"
   },
   {
    "duration": 7801,
    "start_time": "2023-03-29T12:39:05.144Z"
   },
   {
    "duration": 274,
    "start_time": "2023-03-29T12:39:17.058Z"
   },
   {
    "duration": 53,
    "start_time": "2023-03-29T12:40:09.384Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-29T12:41:29.964Z"
   },
   {
    "duration": 1578,
    "start_time": "2023-03-29T12:46:42.114Z"
   },
   {
    "duration": 3291,
    "start_time": "2023-03-29T12:46:43.694Z"
   },
   {
    "duration": 73,
    "start_time": "2023-03-29T12:46:46.987Z"
   },
   {
    "duration": 55,
    "start_time": "2023-03-29T12:46:47.062Z"
   },
   {
    "duration": 167,
    "start_time": "2023-03-29T12:46:47.119Z"
   },
   {
    "duration": 7873,
    "start_time": "2023-03-29T12:46:47.288Z"
   },
   {
    "duration": 45118,
    "start_time": "2023-03-29T12:46:55.163Z"
   },
   {
    "duration": 72,
    "start_time": "2023-03-29T18:03:22.999Z"
   },
   {
    "duration": 215,
    "start_time": "2023-03-29T18:08:18.804Z"
   },
   {
    "duration": 209,
    "start_time": "2023-03-29T18:08:55.660Z"
   },
   {
    "duration": 189,
    "start_time": "2023-03-29T18:09:20.686Z"
   },
   {
    "duration": 189,
    "start_time": "2023-03-29T18:09:59.011Z"
   },
   {
    "duration": 70,
    "start_time": "2023-03-29T18:10:20.512Z"
   },
   {
    "duration": 50,
    "start_time": "2023-03-29T18:10:41.298Z"
   },
   {
    "duration": 90,
    "start_time": "2023-03-29T18:10:46.404Z"
   },
   {
    "duration": 86,
    "start_time": "2023-03-29T18:10:56.271Z"
   },
   {
    "duration": 160,
    "start_time": "2023-03-29T18:12:21.837Z"
   },
   {
    "duration": 169,
    "start_time": "2023-03-29T18:12:31.424Z"
   },
   {
    "duration": 52,
    "start_time": "2023-03-29T18:12:42.932Z"
   },
   {
    "duration": 1702,
    "start_time": "2023-03-29T18:12:55.002Z"
   },
   {
    "duration": 3374,
    "start_time": "2023-03-29T18:12:56.706Z"
   },
   {
    "duration": 74,
    "start_time": "2023-03-29T18:13:00.082Z"
   },
   {
    "duration": 142,
    "start_time": "2023-03-29T18:13:00.158Z"
   },
   {
    "duration": 207,
    "start_time": "2023-03-29T18:13:01.901Z"
   },
   {
    "duration": 821,
    "start_time": "2023-03-29T18:13:03.803Z"
   },
   {
    "duration": 11090,
    "start_time": "2023-03-29T18:13:08.096Z"
   },
   {
    "duration": 1023,
    "start_time": "2023-03-29T18:13:24.270Z"
   },
   {
    "duration": 137,
    "start_time": "2023-03-29T18:13:32.437Z"
   },
   {
    "duration": 1149,
    "start_time": "2023-03-29T18:13:47.801Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-29T18:13:50.922Z"
   },
   {
    "duration": 11104,
    "start_time": "2023-03-29T18:13:58.315Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-29T18:14:09.421Z"
   },
   {
    "duration": 8528058,
    "start_time": "2023-03-29T18:14:09.427Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-29T20:36:17.488Z"
   },
   {
    "duration": 2644,
    "start_time": "2023-03-30T07:23:44.213Z"
   },
   {
    "duration": 727,
    "start_time": "2023-03-30T07:23:46.859Z"
   },
   {
    "duration": 87,
    "start_time": "2023-03-30T07:23:47.588Z"
   },
   {
    "duration": 112,
    "start_time": "2023-03-30T07:23:47.677Z"
   },
   {
    "duration": 212,
    "start_time": "2023-03-30T07:23:52.724Z"
   },
   {
    "duration": 3264,
    "start_time": "2023-03-30T07:23:54.199Z"
   },
   {
    "duration": 4352,
    "start_time": "2023-03-30T07:25:13.886Z"
   },
   {
    "duration": 4375,
    "start_time": "2023-03-30T07:25:18.240Z"
   },
   {
    "duration": 30452,
    "start_time": "2023-03-30T07:25:28.426Z"
   },
   {
    "duration": 174,
    "start_time": "2023-03-30T07:26:04.414Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-30T07:26:16.582Z"
   },
   {
    "duration": 1034661,
    "start_time": "2023-03-30T07:28:07.228Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-30T07:45:21.891Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-30T07:45:21.899Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-30T07:45:21.925Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-30T07:45:21.926Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-30T07:45:21.927Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-30T07:45:21.928Z"
   },
   {
    "duration": 27,
    "start_time": "2023-03-30T07:46:31.567Z"
   },
   {
    "duration": 63,
    "start_time": "2023-03-30T07:46:35.408Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-30T07:47:05.416Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-30T07:47:33.481Z"
   },
   {
    "duration": 67,
    "start_time": "2023-03-30T07:47:43.370Z"
   },
   {
    "duration": 165920,
    "start_time": "2023-03-30T07:47:47.926Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-30T07:50:33.848Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-30T07:50:33.861Z"
   },
   {
    "duration": 754344,
    "start_time": "2023-03-30T07:53:18.045Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-30T08:05:52.395Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-30T08:06:30.097Z"
   },
   {
    "duration": 1148080,
    "start_time": "2023-03-30T08:06:44.801Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-30T08:25:52.889Z"
   },
   {
    "duration": 112,
    "start_time": "2023-03-30T08:25:52.901Z"
   },
   {
    "duration": 63650,
    "start_time": "2023-03-30T08:25:53.015Z"
   },
   {
    "duration": 27,
    "start_time": "2023-03-30T08:26:56.667Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-30T08:26:56.696Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-30T08:27:07.526Z"
   },
   {
    "duration": 20,
    "start_time": "2023-03-30T08:27:41.977Z"
   },
   {
    "duration": 1842094,
    "start_time": "2023-03-30T08:27:54.410Z"
   },
   {
    "duration": 1622238,
    "start_time": "2023-03-30T09:00:26.360Z"
   },
   {
    "duration": 20,
    "start_time": "2023-03-30T09:53:18.653Z"
   },
   {
    "duration": 2788,
    "start_time": "2023-03-30T09:57:26.911Z"
   },
   {
    "duration": 827,
    "start_time": "2023-03-30T09:57:29.702Z"
   },
   {
    "duration": 88,
    "start_time": "2023-03-30T09:57:30.531Z"
   },
   {
    "duration": 171,
    "start_time": "2023-03-30T09:57:30.621Z"
   },
   {
    "duration": 161,
    "start_time": "2023-03-30T09:57:30.795Z"
   },
   {
    "duration": 4704,
    "start_time": "2023-03-30T09:57:30.958Z"
   },
   {
    "duration": 5957,
    "start_time": "2023-03-30T09:57:35.665Z"
   },
   {
    "duration": 2727,
    "start_time": "2023-03-30T09:58:01.490Z"
   },
   {
    "duration": 3522,
    "start_time": "2023-03-30T09:58:04.219Z"
   },
   {
    "duration": 77,
    "start_time": "2023-03-30T09:58:07.743Z"
   },
   {
    "duration": 169,
    "start_time": "2023-03-30T09:58:07.822Z"
   },
   {
    "duration": 232,
    "start_time": "2023-03-30T09:58:07.993Z"
   },
   {
    "duration": 4314,
    "start_time": "2023-03-30T09:58:08.227Z"
   },
   {
    "duration": 5723,
    "start_time": "2023-03-30T09:58:12.543Z"
   },
   {
    "duration": 52,
    "start_time": "2023-03-30T09:58:31.417Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-30T09:58:39.696Z"
   },
   {
    "duration": 2995,
    "start_time": "2023-03-30T09:59:01.089Z"
   },
   {
    "duration": 3625,
    "start_time": "2023-03-30T09:59:05.192Z"
   },
   {
    "duration": 86,
    "start_time": "2023-03-30T09:59:09.784Z"
   },
   {
    "duration": 161,
    "start_time": "2023-03-30T09:59:12.884Z"
   },
   {
    "duration": 239,
    "start_time": "2023-03-30T09:59:14.928Z"
   },
   {
    "duration": 4291,
    "start_time": "2023-03-30T09:59:19.725Z"
   },
   {
    "duration": 5624,
    "start_time": "2023-03-30T09:59:26.670Z"
   },
   {
    "duration": 2813,
    "start_time": "2023-03-30T10:00:18.758Z"
   },
   {
    "duration": 3538,
    "start_time": "2023-03-30T10:00:21.580Z"
   },
   {
    "duration": 79,
    "start_time": "2023-03-30T10:00:25.120Z"
   },
   {
    "duration": 177,
    "start_time": "2023-03-30T10:00:25.202Z"
   },
   {
    "duration": 215,
    "start_time": "2023-03-30T10:00:25.384Z"
   },
   {
    "duration": 4566,
    "start_time": "2023-03-30T10:00:25.600Z"
   },
   {
    "duration": 5765,
    "start_time": "2023-03-30T10:00:30.168Z"
   },
   {
    "duration": 1564,
    "start_time": "2023-03-30T10:00:35.935Z"
   },
   {
    "duration": 191,
    "start_time": "2023-03-30T10:00:57.693Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-30T10:00:58.391Z"
   },
   {
    "duration": 51,
    "start_time": "2023-03-30T10:01:00.615Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-30T10:01:00.668Z"
   },
   {
    "duration": 2757,
    "start_time": "2023-03-30T10:01:26.363Z"
   },
   {
    "duration": 3509,
    "start_time": "2023-03-30T10:01:29.123Z"
   },
   {
    "duration": 75,
    "start_time": "2023-03-30T10:01:32.634Z"
   },
   {
    "duration": 183,
    "start_time": "2023-03-30T10:01:32.711Z"
   },
   {
    "duration": 215,
    "start_time": "2023-03-30T10:01:32.895Z"
   },
   {
    "duration": 3718,
    "start_time": "2023-03-30T10:01:33.112Z"
   },
   {
    "duration": 4687,
    "start_time": "2023-03-30T10:01:36.832Z"
   },
   {
    "duration": 1670,
    "start_time": "2023-03-30T10:01:43.965Z"
   },
   {
    "duration": 1721737,
    "start_time": "2023-03-30T10:01:49.591Z"
   },
   {
    "duration": 63,
    "start_time": "2023-03-30T10:30:31.330Z"
   },
   {
    "duration": 868157,
    "start_time": "2023-03-30T10:30:31.403Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-30T10:44:59.562Z"
   },
   {
    "duration": 37,
    "start_time": "2023-03-30T10:44:59.567Z"
   },
   {
    "duration": 1266437,
    "start_time": "2023-03-30T10:44:59.607Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-30T11:06:06.046Z"
   },
   {
    "duration": 153,
    "start_time": "2023-03-30T11:06:06.052Z"
   },
   {
    "duration": 2923,
    "start_time": "2023-03-30T15:17:36.435Z"
   },
   {
    "duration": 3540,
    "start_time": "2023-03-30T15:17:39.360Z"
   },
   {
    "duration": 84,
    "start_time": "2023-03-30T15:17:42.901Z"
   },
   {
    "duration": 214,
    "start_time": "2023-03-30T15:17:42.988Z"
   },
   {
    "duration": 186,
    "start_time": "2023-03-30T15:17:43.204Z"
   },
   {
    "duration": 3838,
    "start_time": "2023-03-30T15:17:43.392Z"
   },
   {
    "duration": 4787,
    "start_time": "2023-03-30T15:17:47.232Z"
   },
   {
    "duration": 1634,
    "start_time": "2023-03-30T15:17:52.020Z"
   },
   {
    "duration": 402903,
    "start_time": "2023-03-30T15:17:53.656Z"
   },
   {
    "duration": 18,
    "start_time": "2023-03-30T15:24:36.562Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-30T15:24:36.582Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-30T15:24:51.850Z"
   },
   {
    "duration": 1672369,
    "start_time": "2023-03-30T15:25:09.534Z"
   },
   {
    "duration": 22,
    "start_time": "2023-03-30T15:58:52.901Z"
   },
   {
    "duration": 32,
    "start_time": "2023-03-30T15:59:14.490Z"
   },
   {
    "duration": 225,
    "start_time": "2023-03-30T15:59:20.268Z"
   },
   {
    "duration": 60,
    "start_time": "2023-03-30T16:01:18.294Z"
   },
   {
    "duration": 1981,
    "start_time": "2023-03-30T16:02:21.816Z"
   },
   {
    "duration": 4146,
    "start_time": "2023-03-30T16:02:23.800Z"
   },
   {
    "duration": 175,
    "start_time": "2023-03-30T16:02:27.948Z"
   },
   {
    "duration": 255,
    "start_time": "2023-03-30T16:02:28.126Z"
   },
   {
    "duration": 180,
    "start_time": "2023-03-30T16:02:28.384Z"
   },
   {
    "duration": 3894,
    "start_time": "2023-03-30T16:02:28.567Z"
   },
   {
    "duration": 5580,
    "start_time": "2023-03-30T16:02:32.464Z"
   },
   {
    "duration": 1765,
    "start_time": "2023-03-30T16:02:38.046Z"
   },
   {
    "duration": 1643402,
    "start_time": "2023-03-30T16:02:39.813Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-30T16:30:03.219Z"
   },
   {
    "duration": 258,
    "start_time": "2023-03-30T16:30:03.240Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-30T16:30:03.504Z"
   },
   {
    "duration": 242,
    "start_time": "2023-03-30T16:31:30.165Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-30T16:31:42.201Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-30T16:31:45.723Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-30T16:31:49.659Z"
   },
   {
    "duration": 26,
    "start_time": "2023-03-30T16:31:54.072Z"
   },
   {
    "duration": 1773,
    "start_time": "2023-04-01T08:16:25.565Z"
   },
   {
    "duration": 3643,
    "start_time": "2023-04-01T08:16:27.340Z"
   },
   {
    "duration": 124,
    "start_time": "2023-04-01T08:16:30.985Z"
   },
   {
    "duration": 172,
    "start_time": "2023-04-01T08:16:31.110Z"
   },
   {
    "duration": 68,
    "start_time": "2023-04-01T08:16:38.687Z"
   },
   {
    "duration": 132,
    "start_time": "2023-04-01T08:17:10.438Z"
   },
   {
    "duration": 64,
    "start_time": "2023-04-01T08:17:31.483Z"
   },
   {
    "duration": 97,
    "start_time": "2023-04-01T08:17:40.814Z"
   },
   {
    "duration": 110,
    "start_time": "2023-04-01T08:17:45.858Z"
   },
   {
    "duration": 111,
    "start_time": "2023-04-01T08:17:49.946Z"
   },
   {
    "duration": 2746,
    "start_time": "2023-04-01T08:21:22.158Z"
   },
   {
    "duration": 3988,
    "start_time": "2023-04-01T08:21:36.535Z"
   },
   {
    "duration": 1391,
    "start_time": "2023-04-01T08:21:40.525Z"
   },
   {
    "duration": 1476,
    "start_time": "2023-04-01T08:21:49.298Z"
   },
   {
    "duration": 107,
    "start_time": "2023-04-01T08:22:27.675Z"
   },
   {
    "duration": 1366,
    "start_time": "2023-04-01T08:22:36.706Z"
   },
   {
    "duration": 3849,
    "start_time": "2023-04-01T08:22:41.061Z"
   },
   {
    "duration": 1648,
    "start_time": "2023-04-01T08:22:50.891Z"
   },
   {
    "duration": 2141,
    "start_time": "2023-04-01T08:23:08.888Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-01T08:23:11.031Z"
   },
   {
    "duration": 729,
    "start_time": "2023-04-01T08:23:11.037Z"
   },
   {
    "duration": 80,
    "start_time": "2023-04-01T08:23:11.767Z"
   },
   {
    "duration": 124,
    "start_time": "2023-04-01T08:23:11.849Z"
   },
   {
    "duration": 216,
    "start_time": "2023-04-01T08:23:11.975Z"
   },
   {
    "duration": 2609,
    "start_time": "2023-04-01T08:23:12.193Z"
   },
   {
    "duration": 1413,
    "start_time": "2023-04-01T08:23:20.957Z"
   },
   {
    "duration": 2612,
    "start_time": "2023-05-27T10:23:25.841Z"
   },
   {
    "duration": 1813,
    "start_time": "2023-05-27T10:23:28.455Z"
   },
   {
    "duration": 217,
    "start_time": "2023-05-27T10:23:30.269Z"
   },
   {
    "duration": 2197,
    "start_time": "2023-05-27T10:23:30.488Z"
   },
   {
    "duration": 68,
    "start_time": "2023-05-27T10:23:32.687Z"
   },
   {
    "duration": 933080,
    "start_time": "2023-05-27T10:23:32.757Z"
   },
   {
    "duration": 103,
    "start_time": "2023-05-27T10:39:05.839Z"
   },
   {
    "duration": 2626,
    "start_time": "2023-05-27T10:39:05.944Z"
   },
   {
    "duration": 1473,
    "start_time": "2023-05-27T10:39:08.572Z"
   }
  ],
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "146.989px",
    "width": "224.986px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aed52d2-cdda-4261-b1f2-1a7392c8de6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prophet in /opt/conda/lib/python3.11/site-packages (1.1.4)\n",
      "Requirement already satisfied: cmdstanpy>=1.0.4 in /opt/conda/lib/python3.11/site-packages (from prophet) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.11/site-packages (from prophet) (1.24.4)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from prophet) (3.7.2)\n",
      "Requirement already satisfied: pandas>=1.0.4 in /opt/conda/lib/python3.11/site-packages (from prophet) (1.5.3)\n",
      "Requirement already satisfied: LunarCalendar>=0.0.9 in /opt/conda/lib/python3.11/site-packages (from prophet) (0.0.9)\n",
      "Requirement already satisfied: convertdate>=2.1.2 in /opt/conda/lib/python3.11/site-packages (from prophet) (2.4.0)\n",
      "Requirement already satisfied: holidays>=0.25 in /opt/conda/lib/python3.11/site-packages (from prophet) (0.33)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/conda/lib/python3.11/site-packages (from prophet) (2.8.2)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /opt/conda/lib/python3.11/site-packages (from prophet) (4.66.1)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.11/site-packages (from prophet) (6.0.1)\n",
      "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /opt/conda/lib/python3.11/site-packages (from convertdate>=2.1.2->prophet) (0.5.12)\n",
      "Requirement already satisfied: ephem>=3.7.5.3 in /opt/conda/lib/python3.11/site-packages (from LunarCalendar>=0.0.9->prophet) (4.1.4)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from LunarCalendar>=0.0.9->prophet) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->prophet) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->prophet) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->prophet) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->prophet) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->prophet) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=2.0.0->prophet) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.0->prophet) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e55604-8ceb-4e4d-bbce-040128d8890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "from prophet import Prophet\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc28b15b-9881-49bd-aa24-4b81886148ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SPARK_MASTER_IP = '172.18.0.2' \n",
    "spark = SparkSession.builder.appName(\"pyspark-taxi-forecasting\") \\\n",
    "    .master(f\"spark://{SPARK_MASTER_IP}:7077\") \\\n",
    "    .config(\"spark.executor.cores\", 3) \\\n",
    "    .config('spark.local.dir', 'spark_tmp/') \\\n",
    "    .config(\"spark.task.cpus\", 3) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b4371b-f112-4eda-b558-3932de95d341",
   "metadata": {},
   "source": [
    "spark = SparkSession.builder.appName(\"Introduction to Spark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef0d79f-5126-483d-8f9a-14962bc2f332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://915d12b4f63b:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://172.18.0.2:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-taxi-forecasting</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f5b1c0c3150>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378cb8d6-a943-4ccc-9fa4-cebcf38b8627",
   "metadata": {},
   "source": [
    "# Обучение модели и предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34361bae-adab-4814-815c-2110e0b5daec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_hours = spark.read.csv(\"all_hours_short_v2.csv\", header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4d4f275-fc74-41e7-8d5c-2ee6ba3a4e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.read.csv(\"y_true_2023-07-31_23-00_UTC0.csv\", header = True, inferSchema = True)\n",
    "test = test.withColumn('ds', test['hours']) \\\n",
    "    .withColumn('pickup_community_area', test['Pickup Community Area']) \\\n",
    "    .withColumn('y', test['trips_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ec5a9ca-6dbd-4760-9bed-71d87c5a2c69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_list = [\"pickup_community_area\"]\n",
    "  \n",
    "\n",
    "Windowspec = Window.partitionBy([\"pickup_community_area\"]).orderBy(all_hours.hour_cons.desc())\n",
    "  \n",
    "all_hours_lagged = all_hours.withColumn(\n",
    "    'med_cost_lagged1', lag(all_hours['cost_median'], -1).over(Windowspec)).withColumn(\n",
    "    'med_miles_lagged1', lag(all_hours['miles_median'], -1).over(Windowspec)).withColumn(\n",
    "    'med_seconds_lagged1', lag(all_hours['seconds_median'], -1).over(Windowspec)).withColumn(\n",
    "    'trips_count_lagged1', lag(all_hours['trips_count'], -1).over(Windowspec)).withColumn(\n",
    "    'trips_count_lagged2', lag(all_hours['trips_count'], -2).over(Windowspec)).withColumn(\n",
    "    'trips_count_lagged3', lag(all_hours['trips_count'], -3).over(Windowspec)).withColumn(\n",
    "    'trips_count_lagged12', lag(all_hours['trips_count'], -12).over(Windowspec)).withColumn(\n",
    "    'trips_count_lagged24', lag(all_hours['trips_count'], -24).over(Windowspec)).withColumn(\n",
    "    'trips_count_lagged_week', lag(all_hours['trips_count'], -24*7).over(Windowspec))\n",
    "\n",
    "all_hours_lagged = all_hours_lagged.withColumn(\n",
    "    'rolling_average_on3hours', avg(all_hours_lagged['trips_count_lagged1'],).over(Windowspec.rowsBetween(-3, -0))) \\\n",
    "    .withColumn('rolling_average_on24hours', avg(all_hours_lagged['trips_count_lagged1'],).over(Windowspec.rowsBetween(-24, -0))) \\\n",
    "    .na.drop('any').cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ddda5e-dfc8-462c-a399-e4ccf22fdafd",
   "metadata": {},
   "source": [
    "# Проведем предсказания с помощью модели Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732965c6-6c35-44ee-8860-2852098fe845",
   "metadata": {},
   "source": [
    "## Разделим данные для Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d02f5ceb-42f5-402d-a472-cc05d3a7d16e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "InMemoryTableScan [pickup_community_area#18, ds#357, y#358]\n",
      "   +- InMemoryRelation [pickup_community_area#18, ds#357, y#358], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "         +- Exchange hashpartitioning(pickup_community_area#18, 9), REPARTITION_BY_NUM, [plan_id=115]\n",
      "            +- *(1) Project [pickup_community_area#18, hour_cons#19 AS ds#357, trips_count#21 AS y#358]\n",
      "               +- *(1) Filter (isnotnull(hour_cons#19) AND (hour_cons#19 < 2023-07-31 23:00:00))\n",
      "                  +- InMemoryTableScan [hour_cons#19, pickup_community_area#18, trips_count#21], [isnotnull(hour_cons#19), (hour_cons#19 < 2023-07-31 23:00:00)]\n",
      "                        +- InMemoryRelation [_c0#17, pickup_community_area#18, hour_cons#19, taxi_countdist#20, trips_count#21, cost_median#22, miles_median#23, seconds_median#24, med_cost_lagged1#75, med_miles_lagged1#86, med_seconds_lagged1#97, trips_count_lagged1#109, trips_count_lagged2#122, trips_count_lagged3#136, trips_count_lagged12#151, trips_count_lagged24#167, trips_count_lagged_week#184, rolling_average_on3hours#203, rolling_average_on24hours#223], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                              +- *(2) Filter atleastnnonnulls(19, _c0#17, pickup_community_area#18, hour_cons#19, taxi_countdist#20, trips_count#21, cost_median#22, miles_median#23, seconds_median#24, med_cost_lagged1#75, med_miles_lagged1#86, med_seconds_lagged1#97, trips_count_lagged1#109, trips_count_lagged2#122, trips_count_lagged3#136, trips_count_lagged12#151, trips_count_lagged24#167, trips_count_lagged_week#184, rolling_average_on3hours#203, rolling_average_on24hours#223)\n",
      "                                 +- Window [lag(trips_count#21, 168, null) windowspecdefinition(pickup_community_area#18, hour_cons#19 DESC NULLS LAST, specifiedwindowframe(RowFrame, 168, 168)) AS trips_count_lagged_week#184, avg(trips_count_lagged1#109) windowspecdefinition(pickup_community_area#18, hour_cons#19 DESC NULLS LAST, specifiedwindowframe(RowFrame, -3, currentrow$())) AS rolling_average_on3hours#203, avg(trips_count_lagged1#109) windowspecdefinition(pickup_community_area#18, hour_cons#19 DESC NULLS LAST, specifiedwindowframe(RowFrame, -24, currentrow$())) AS rolling_average_on24hours#223], [pickup_community_area#18], [hour_cons#19 DESC NULLS LAST]\n",
      "                                    +- Window [lag(cost_median#22, 1, null) windowspecdefinition(pickup_community_area#18, hour_cons#19 DESC NULLS LAST, specifiedwindowframe(RowFrame, 1, 1)) AS med_cost_lagged1#75, lag(miles_median#23, 1, null) windowspecdefinition(pickup_community_area#18, hour_cons#19 DESC NULLS LAST, specifiedwindowframe(RowFrame, 1, 1)) AS med_miles_lagged1#86, lag(seconds_median#24, 1, null) windowspecdefinition(pickup_community_area#18, hour_cons#19 DESC NULLS LAST, specifiedwindowframe(RowFrame, 1, 1)) AS med_seconds_lagged1#97, lag(trips_count#21, 1, null) windowspecdefinition(pickup_community_area#18, hour_cons#19 DESC NULLS LAST, specifiedwindowframe(RowFrame, 1, 1)) AS trips_count_lagged1#109, lag(trips_count#21, 2, null) windowspecdefinition(pickup_community_area#18, hour_cons#19 DESC NULLS LAST, specifiedwindowframe(RowFrame, 2, 2)) AS trips_count_lagged2#122, lag(trips_count#21, 3, null) windowspecdefinition(pickup_community_area#18, hour_cons#19 DESC NULLS LAST, specifiedwindowframe(RowFrame, 3, 3)) AS trips_count_lagged3#136, lag(trips_count#21, 12, null) windowspecdefinition(pickup_community_area#18, hour_cons#19 DESC NULLS LAST, specifiedwindowframe(RowFrame, 12, 12)) AS trips_count_lagged12#151, lag(trips_count#21, 24, null) windowspecdefinition(pickup_community_area#18, hour_cons#19 DESC NULLS LAST, specifiedwindowframe(RowFrame, 24, 24)) AS trips_count_lagged24#167], [pickup_community_area#18], [hour_cons#19 DESC NULLS LAST]\n",
      "                                       +- *(1) Sort [pickup_community_area#18 ASC NULLS FIRST, hour_cons#19 DESC NULLS LAST], false, 0\n",
      "                                          +- Exchange hashpartitioning(pickup_community_area#18, 200), ENSURE_REQUIREMENTS, [plan_id=98]\n",
      "                                             +- FileScan csv [_c0#17,pickup_community_area#18,hour_cons#19,taxi_countdist#20,trips_count#21,cost_median#22,miles_median#23,seconds_median#24] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/work/all_hours_short_v2.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<_c0:int,pickup_community_area:int,hour_cons:timestamp,taxi_countdist:int,trips_count:int,c...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_proph = all_hours_lagged.filter((all_hours_lagged.hour_cons < '2023-07-31 23:00:00')) \\\n",
    "    .selectExpr( 'pickup_community_area',\n",
    "    'hour_cons as ds', 'trips_count as y')\n",
    "# Partition the data dfsp_partitionned\n",
    "train_proph.createOrReplaceTempView(\"pickup_community_area\")\n",
    "sql = \"select * from pickup_community_area\"\n",
    "train_proph = (spark.sql(sql)\\\n",
    "   .repartition(spark.sparkContext.defaultParallelism, \n",
    "   ['pickup_community_area'])).cache()\n",
    "train_proph.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27000ffe-4e7d-4ca9-902f-55daa0fadf31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_proph = all_hours_lagged.filter(all_hours_lagged.hour_cons == '2023-07-31 23:00:00') \\\n",
    "    .selectExpr( 'pickup_community_area',\n",
    "    'hour_cons as ds', 'trips_count as y') \n",
    "    #.withColumn(\"y\",col(\"y\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b3c9e-2dde-4228-901f-9c88782f82a1",
   "metadata": {},
   "source": [
    "## Проведем обучение и предсказание модели через функцию Pandas_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d72de43f-2cea-4a4c-a8ff-1d71e5cf965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a schema\n",
    "schema = StructType([ \\\n",
    "                     StructField('pickup_community_area', IntegerType()), \n",
    "                     StructField('ds', TimestampType()),\n",
    "                     StructField('y', FloatType()),\n",
    "                     StructField('yhat', DoubleType()),\n",
    "                     StructField('daily', DoubleType()),\n",
    "                     StructField('weekly', DoubleType())\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4230fe35-c305-417b-b38e-28b909969b72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/group_ops.py:103: UserWarning: It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# define the Pandas UDF\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "def apply_model(store_pd):  # instantiate the model and set parameters\n",
    "  model = Prophet(\n",
    "      interval_width=0.95,\n",
    "      growth='linear',\n",
    "      n_changepoints = 150,\n",
    "      daily_seasonality=True,\n",
    "      weekly_seasonality=True,\n",
    "      yearly_seasonality=True,\n",
    "      seasonality_mode='additive'\n",
    "  )  # fit the model to historical data\n",
    "  model.fit(store_pd)  # Create a data frame that lists 90 dates starting from Jan 1 2018\n",
    "  future = model.make_future_dataframe(\n",
    "      periods=1, #test_proph.filter(test_proph.pickup_community_area==community_num).count(),\n",
    "      freq='h',\n",
    "      include_history=True\n",
    "   )  # Out of sample prediction\n",
    "  prediction = model.predict(future)  # Create a data frame that contains store, item, y, and yhat\n",
    "  f_pd = prediction[['ds', 'yhat', 'daily', 'weekly']]\n",
    "  st_pd = store_pd[['ds', 'pickup_community_area', 'y']]\n",
    "  result_pd = f_pd.join(st_pd.set_index('ds'), on='ds', how='left')  # fill store and item\n",
    "  result_pd['pickup_community_area'] = store_pd['pickup_community_area'].iloc[0]\n",
    "  return result_pd[['pickup_community_area', 'ds', 'y', 'yhat',\n",
    "                    'daily', 'weekly']]# Apply the function to all store-items\n",
    "# Print the results - calculate the time to run\n",
    "results = train_proph.groupby(['pickup_community_area']).apply(apply_model).cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66540195-a636-41ef-8fd1-0f0a4ed5a26c",
   "metadata": {},
   "source": [
    "# Создадим признаки задерки и скользящего среднего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89233e8f-af0f-48d7-adfe-b11098d21fc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_list = [\"pickup_community_area\"]\n",
    "  \n",
    "\n",
    "Windowspec = Window.partitionBy([\"pickup_community_area\"]).orderBy(all_hours.hour_cons.desc())\n",
    "  \n",
    "all_hours_lagged = all_hours.withColumn(\n",
    "    'med_cost_lagged1', lag(all_hours['cost_median'], -1).over(Windowspec)).withColumn(\n",
    "    'med_miles_lagged1', lag(all_hours['miles_median'], -1).over(Windowspec)).withColumn(\n",
    "    'med_seconds_lagged1', lag(all_hours['seconds_median'], -1).over(Windowspec)).withColumn(\n",
    "    'trips_count_lagged1', lag(all_hours['trips_count'], -1).over(Windowspec)).withColumn(\n",
    "    'trips_count_lagged2', lag(all_hours['trips_count'], -2).over(Windowspec)).withColumn(\n",
    "    'trips_count_lagged3', lag(all_hours['trips_count'], -3).over(Windowspec)).withColumn(\n",
    "    'trips_count_lagged12', lag(all_hours['trips_count'], -12).over(Windowspec)).withColumn(\n",
    "    'trips_count_lagged24', lag(all_hours['trips_count'], -24).over(Windowspec)).withColumn(\n",
    "    'trips_count_lagged_week', lag(all_hours['trips_count'], -24*7).over(Windowspec))\n",
    "\n",
    "all_hours_lagged = all_hours_lagged.withColumn(\n",
    "    'rolling_average_on3hours', avg(all_hours_lagged['trips_count_lagged1'],).over(Windowspec.rowsBetween(-3, -0))) \\\n",
    "    .withColumn('rolling_average_on24hours', avg(all_hours_lagged['trips_count_lagged1'],).over(Windowspec.rowsBetween(-24, -0))) \\\n",
    "    .na.drop('any').cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576796b5-e132-43bb-b5af-65ceccea78e0",
   "metadata": {},
   "source": [
    "# Проведем обучение и окончательные предсказания с помощью линейной регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553aa7aa-26b1-4abb-82a9-b9ac4969e553",
   "metadata": {},
   "source": [
    "## Выделим тренировочную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c7cb428-3f92-4438-bd34-89e1262bbdd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_lr = all_hours_lagged.filter((all_hours_lagged.hour_cons < '2023-07-31 23:00:00')) \\\n",
    "    .selectExpr( 'pickup_community_area',\n",
    "    'med_cost_lagged1','med_miles_lagged1','med_seconds_lagged1',\n",
    "    'trips_count_lagged1', 'trips_count_lagged2', 'trips_count_lagged3', \n",
    "    'trips_count_lagged12', 'trips_count_lagged24','trips_count_lagged_week',\n",
    "    'rolling_average_on3hours',\n",
    "    'rolling_average_on24hours',\n",
    "    'hour_cons as ds', 'trips_count as y') \\\n",
    "        .join(results['pickup_community_area', 'ds', 'daily', 'weekly'], on=['ds','pickup_community_area'] , how='inner'\n",
    "             ).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c88a00b-7552-4e46-9d01-c927df527474",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureCols = [\n",
    "    'med_cost_lagged1','med_miles_lagged1','med_seconds_lagged1',\n",
    "    'trips_count_lagged1', 'trips_count_lagged2', 'trips_count_lagged3', \n",
    "    'trips_count_lagged12', 'trips_count_lagged24','trips_count_lagged_week',\n",
    "    'rolling_average_on3hours',\n",
    "    'rolling_average_on24hours',\n",
    "     'daily', 'weekly'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "004e72ee-3dc1-4ac4-bdbd-b5d108260723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_lr = all_hours_lagged.filter(all_hours_lagged.hour_cons == '2023-07-31 23:00:00') \\\n",
    "    .selectExpr('pickup_community_area',\n",
    "    'med_cost_lagged1','med_miles_lagged1','med_seconds_lagged1',\n",
    "    'trips_count_lagged1', 'trips_count_lagged2', 'trips_count_lagged3', \n",
    "    'trips_count_lagged12', 'trips_count_lagged24','trips_count_lagged_week',\n",
    "    'rolling_average_on3hours',\n",
    "    'rolling_average_on24hours',\n",
    "    'hour_cons as ds', 'trips_count as y') \\\n",
    "        .join(results['pickup_community_area', 'ds', 'daily', 'weekly'], on=['ds','pickup_community_area'] , how='inner'\n",
    "             ).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184815fc-7e75-42cd-bd7c-2e54be91e7da",
   "metadata": {},
   "source": [
    "## Создадим pipeline и evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c56d02-7589-482f-9f67-8a651f315746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# положить фичи в вектор\n",
    "assembler = VectorAssembler(inputCols=featureCols, outputCol=\"features\") \n",
    "standardScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\", withStd = True)\n",
    "lr = (LinearRegression(featuresCol='features_scaled', labelCol=\"y\", predictionCol='y_pred')) \n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, standardScaler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5a5a87b-4394-4cb2-b1bb-2034dcec9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(predictionCol=\"y_pred\", labelCol='y', metricName='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05019fb-1b18-4c83-9771-5b1b029d7479",
   "metadata": {},
   "source": [
    "# Реализуем регрессию для каждого региона через функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e6fea47-f09a-4785-b475-d59cd311e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelsandpredictions(func_community):\n",
    "        \n",
    "    temp_train = train_lr.filter(train_lr.pickup_community_area == func_community)\n",
    "    temp_test = test_lr.filter(test_lr.pickup_community_area == func_community)\n",
    "    \n",
    "    temp_lr = pipeline.fit(temp_train)\n",
    "    temp_pred = temp_lr.transform(temp_test)\n",
    "    temp_predandtrue = temp_pred.select(\n",
    "                                        'pickup_community_area',\n",
    "                                        'ds',\n",
    "                                        \"y_pred\"\n",
    "                                        ).withColumn(\"y_pred\",F.round(temp_pred[\"y_pred\"],0)) \n",
    "    temp_predandtrue = temp_predandtrue.withColumn('y_pred', F.when((F.col(\"y_pred\") <= 0), 0)\\\n",
    "        .otherwise(temp_predandtrue.y_pred)).cache()\n",
    "    #temp_lr = lr.fit(temp_train.union(temp_test))\n",
    "    #temp_lr.write().overwrite().save(\"/models/lr{0}\".format(i))\n",
    "    return temp_predandtrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef748e3e-e3c3-40a2-be68-9a0354b65f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_schema = StructType([ \\\n",
    "    StructField(\"pickup_community_area\",IntegerType (),True), \\\n",
    "    StructField(\"ds\",TimestampType(),True), \\\n",
    "    StructField(\"y_pred\",FloatType(),True) \\\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830290a4-9915-458f-bae6-827593676b1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "test_preds = spark.createDataFrame([],preds_schema)\n",
    "for i in range(78):\n",
    "    test_preds = test_preds.union(modelsandpredictions(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c83316d-eeba-472e-a1fa-aeaf28dd9b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trueandpreds = test.join(test_preds, on=['ds','pickup_community_area'], how='inner') \\\n",
    "    .select(\n",
    "        test.ds,\n",
    "        test.pickup_community_area,\n",
    "        test.y,\n",
    "        test_preds.y_pred).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abd494-2eaa-4d2c-95f3-ee18eb7c2c53",
   "metadata": {},
   "source": [
    "## Посмотрим финальные предсказания и оценим их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa833bdb-e5fe-4735-b397-c191a613520b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "trueandpreds.sort(trueandpreds.pickup_community_area.desc()).show(80)\n",
    "print(\"LinearRegression MAE: {0}\".format(evaluator.evaluate(trueandpreds)))\n",
    "print('MAPE:',\n",
    "    trueandpreds.select(avg((100*abs((trueandpreds.y - trueandpreds.y_pred) / trueandpreds.y)))).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edf55a0-258e-4202-9448-5df2b5a3530a",
   "metadata": {},
   "source": [
    "    Окончательные ошибки отдельных Линейных регрессий для каждого района составили\n",
    "    МАЕ: 2.1025641025641026\n",
    "    МАРЕ: 65.79573756314875\n",
    "\n",
    "    Возможно, тестовые данные были обработаны иначе. Необходимо определить и скоординировать в частности, работу с пропусками и заполнение района 0 в тестовых и тренировочных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1561f2d8-5c09-4dea-95ff-09cc5e9173d0",
   "metadata": {},
   "source": [
    "1,93 когда заполнил пропуски в community area на 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becba951-cf48-405a-aa0d-0dd7ba96f266",
   "metadata": {},
   "source": [
    "1.9230769230769231 - когда не заполнял пропуски в длительности, расстоянии и стоимости и при отсечке по квантилям 0,99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa67a06-af4b-4a1a-a2dc-5fd045db7329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
